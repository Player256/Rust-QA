{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(file_path):\n",
    "    with open(file_path) as file:\n",
    "        json_data = json.load(file)\n",
    "        data = json_data[\"data\"][0][\"paragraphs\"]\n",
    "        \n",
    "    dataset = []\n",
    "    for page in data:\n",
    "        context = page[\"context\"]\n",
    "        for qa in page[\"qas\"]:\n",
    "            question = qa[\"question\"]\n",
    "            for ans in qa[\"answers\"]:\n",
    "                answer = ans[\"text\"]\n",
    "                dataset.append({\n",
    "                    \"context\": context,\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer\n",
    "                })\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 854\n",
      "len(validation_dataset): 107\n",
      "len(test_dataset): 107\n"
     ]
    }
   ],
   "source": [
    "train_dataset_file_path = \"/home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/train_dataset.json\"\n",
    "validation_dataset_file_path = \"/home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/validation_dataset.json\"\n",
    "test_dataset_file_path = \"/home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/test_dataset.json\"\n",
    "\n",
    "\n",
    "train_dataset = build_dataset(file_path=train_dataset_file_path)\n",
    "validation_dataset = build_dataset(file_path=validation_dataset_file_path)\n",
    "test_dataset = build_dataset(file_path=test_dataset_file_path)\n",
    "\n",
    "\n",
    "print(f\"len(train_dataset): {len(train_dataset)}\")\n",
    "print(f\"len(validation_dataset): {len(validation_dataset)}\")\n",
    "print(f\"len(test_dataset): {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to: /home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/train_dataset_processed.json\n",
      "file saved to: /home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/validation_dataset_processed.json\n",
      "file saved to: /home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/test_dataset_processed.json\n"
     ]
    }
   ],
   "source": [
    "# writing to files\n",
    "\n",
    "def save_dataset(file_path, dataset):\n",
    "    try:\n",
    "        paths = file_path.split(\".\")\n",
    "        file_path = paths[0] + \"_processed.\" + paths[1]\n",
    "        with open(file_path, \"w\") as outfile:\n",
    "            outfile.write(json.dumps(dataset, indent=4))\n",
    "        print(f\"file saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "save_dataset(file_path=train_dataset_file_path, dataset=train_dataset)\n",
    "save_dataset(file_path=validation_dataset_file_path, dataset=validation_dataset)\n",
    "save_dataset(file_path=test_dataset_file_path, dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_path):\n",
    "    with open(file_path) as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    data_processed = []\n",
    "    for item in data:\n",
    "        system_message = \"\"\"You are an expert of the Rust language. Please answer question based on the context below.\n",
    "    Context: {context}\"\"\".format(context=item[\"context\"])\n",
    "        user_message = \"\"\"Question: {question}\"\"\".format(question=item[\"question\"])\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message}, \n",
    "            {\"role\": \"user\", \"content\": user_message}, \n",
    "            {\"role\": \"assistant\", \"content\": item[\"answer\"]}\n",
    "        ]\n",
    "        data_processed.append({\"messages\": messages})\n",
    "    \n",
    "    return data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to: /home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/train_dataset_processed_processed.json\n",
      "file saved to: /home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/validation_dataset_processed_processed.json\n",
      "file saved to: /home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/test_dataset_processed_processed.json\n"
     ]
    }
   ],
   "source": [
    "# process and save dataset \n",
    "\n",
    "train_dataset_file_path = \"/home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/train_dataset_processed.json\"\n",
    "validation_dataset_file_path = \"/home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/validation_dataset_processed.json\"\n",
    "test_dataset_file_path = \"/home/ubuntu/random-stuff/ashish/wasmedge/llm-coding-assistant/dataset/test_dataset_processed.json\"\n",
    "\n",
    "\n",
    "train_dataset = process_dataset(file_path=train_dataset_file_path)\n",
    "validation_dataset = process_dataset(file_path=validation_dataset_file_path)\n",
    "test_dataset = process_dataset(file_path=test_dataset_file_path)\n",
    "\n",
    "save_dataset(file_path=train_dataset_file_path, dataset=train_dataset)\n",
    "save_dataset(file_path=validation_dataset_file_path, dataset=validation_dataset)\n",
    "save_dataset(file_path=test_dataset_file_path, dataset=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
